/*******************************************************************************
License:
This software was developed at the National Institute of Standards and
Technology (NIST) by employees of the Federal Government in the course
of their official duties. Pursuant to title 17 Section 105 of the
United States Code, this software is not subject to copyright protection
and is in the public domain. NIST assumes no responsibility  whatsoever for
its use by other parties, and makes no guarantees, expressed or implied,
about its quality, reliability, or any other characteristic.

This software has been determined to be outside the scope of the EAR
(see Part 734.3 of the EAR for exact details) as it has been created solely
by employees of the U.S. Government; it is freely distributed with no
licensing requirements; and it is considered public domain. Therefore,
it is permissible to distribute this software as a free download from the
internet.

Disclaimer:
This software was developed to promote biometric standards and biometric
technology testing for the Federal Government in accordance with the USA
PATRIOT Act and the Enhanced Border Security and Visa Entry Reform Act.
Specific hardware and software products identified in this software were used
in order to perform the software development.  In no case does such
identification imply recommendation or endorsement by the National Institute
of Standards and Technology, nor does it imply that the products and equipment
identified are necessarily the best available for the purpose.
*******************************************************************************/
#include "corresponding_points_pairs.h"
#include "nfrl_lib.h"
#include "opencv_procs.h"
#include "overlap_registered_images.h"
#include "points_on_images.h"

#include <opencv2/opencv.hpp>
#include <opencv2/core/core.hpp>

#include <fstream>
#include <regex>


#ifdef USE_OPENCV
  namespace NFRL {
#else
  namespace NFRL_ITL {
#endif

/** @brief Initialization function that resets all values, not yet implemented. */
void Registrator::Init() {}

/** Copy function to clone a Registrator object, not yet implemented. */
void Registrator::Copy( const Registrator& ) {}

/** Default constructor.  Not usable; supports compilation only. */
Registrator::Registrator() : _correspondingPoints(_correspondingPoints),
                             _metadata(_metadata) {}

/**
 * @brief This class implements the NIST Fingerprint Registration Library.
 *
 * Each image used in a registration process may be referred to using multiple
 * terms: moving or source, and, target, fixed, or sensed.  For the purpose
 * of this discussion, the Fixed image remains fixed in 2-dimensional space
 * and the Moving image is “moved” to align, that is to register, with the
 * Fixed image.
 *
 * The rigid-registration is performed in two steps in order:
 * 1. translate
 * 2. rotate
 *
 * Registered images are subsequently overlaid to determine the smallest
 * rectangle that contains the most amount of fingerprint common to both.
 * This Region of Interest (rectangle) is the area that is used to crop the
 * moving and fixed images.
 *
 * These images are generated:
 *   - Moving image that is cropped and registered to the Fixed image
 *   - cropped, Fixed image
 *   - padded, registered Moving image, grayscale
 *   - padded, Fixed image, grayscale (per the registration)
 *   - overlaid padded and registered images, in color, for visual inspection
 *     of registration result.
 *
 * Note that the corresponding points and metadata variables are passed by
 * reference.  This supports the potential for a corresponding-points-selection
 * 'retry' capability.  These two vectors may be cleared prior to each call
 * of the performRegistration() function.
 *
 * If any control-point in the pair of corresponding points is identical, then
 * the calculation of the CropROI will fail, i.e., the area of crop region will
 * be zero.  While the area=0 is not the problem, its application to perform
 * the crop is what fails.  Therefore, check for "overlapping" control-points.
 *
 * Note that input imagery is preferred to be 8-bit grayscale.
 *
 * @param imgMoving IN 8-bit grayscale image to be registered with imgFixed
 * @param imgFixed IN 8-bit grayscale image to be registered-against
 *                 (by imgMoving)
 * @param correspondingPoints IN list of corresponding control points used
 *                            to perform the registration
 * @param metadata OUT reference to list of logging data generated by the
 *                 performRegistration() function
 * @throw NFRL::Miscue for empty image or overlapping control-points
 */
Registrator::Registrator( std::vector<uint8_t> imgMoving,
                          std::vector<uint8_t> imgFixed,
                          std::vector<int> &correspondingPoints,
                          std::vector<std::string> &metadata )
  : _imgMoving(imgMoving), _imgFixed(imgFixed),
    _correspondingPoints(correspondingPoints), _metadata(metadata)
{
  // Check input parameters
  if( _imgMoving.empty() )
    throw NFRL::Miscue( "moving img buffer is empty" );
  if( _imgFixed.empty() )
    throw NFRL::Miscue( "fixed img buffer is empty" );
}

/** @brief Copy constructor.  This is called when passing the object by value
 *   as parameter to Registrator constructor.
 * 
 * @param Registrator object to be copied
 */
Registrator::Registrator( const Registrator& ) :
    _correspondingPoints(_correspondingPoints), _metadata(_metadata) {}


/**
 * @brief Retrieves the padded, colorized, overlaid, registered image from memory.
 *
 * @return byte-stream
 */
std::vector<uint8_t> Registrator::getColorOverlaidRegisteredImages()
{
  return _vecColorOverlaidRegisteredImages;
}

/**
 * @brief Retrieves the cropped, registered image (that was moved) from memory.
 *
 * @return byte-stream
 */
std::vector<uint8_t> Registrator::getCroppedRegisteredImage()
{
  return _vecCroppedRegisteredImage;
}

/** @brief Retrieves the cropped, fixed image from memory.
 *
 * @return byte-stream
 */
std::vector<uint8_t> Registrator::getCroppedFixedImage()
{
  return _vecCroppedFixedImage;
}

/** @brief Retrieves the padded, grayscale Fixed image from memory.
 *
 * @return byte-stream
 */
std::vector<uint8_t> Registrator::getPaddedFixedImg()
{
  return _vecPaddedFixedImg;
}

/**
 * @brief Retrieves the padded, registered, grayscale Moving image from memory.
 *
 * @return byte-stream
 */
std::vector<uint8_t> Registrator::getPaddedRegisteredMovingImg()
{
  return _vecPaddedRegisteredMovingImg;
}

/**
 * @brief Retrieves the blob region from which ROI coords were calculated.
 *
 * This is a PNG-compressed image.
 * 
 * @return byte-stream
 */
std::vector<uint8_t> Registrator::getPngBlob()
{
  return _vecPngBlob;
}


/**
 * @brief  Enable the using software the option to save image to disk.
 *
 * @param path location on file system to save image file
 *
 * @throw NFRL::Miscue for invalid path, corrupted image buffer
 */
void Registrator::saveCroppedRegisteredImageToDisk( const std::string path ) const
{
  std::vector<int> compression_params;
  compression_params.push_back(cv::IMWRITE_PNG_COMPRESSION);
  compression_params.push_back(9);

  bool result = false;
  try {
    cv::Mat img = cv::imdecode( cv::Mat(_vecCroppedRegisteredImage),
                                cv::IMREAD_UNCHANGED );
    result = cv::imwrite( path, img );
  }
  catch( const cv::Exception& ex ) {
    std::string err{"OpenCV cannot save image: '"};
    err.append( path + "'\n" );
    err.append( ex.what() );
    throw NFRL::Miscue( err );
  }

  if( !result ) {
    std::string err{"OpenCV cannot save image: "};
    err.append( path );
    throw NFRL::Miscue( err );
  }
}


/**
 * @brief  Enable the using software the option to save image to disk.
 *
 * @param path location on file system to save image file
 *
 * @throw NFRL::Miscue for invalid path, corrupted image buffer
 */
void Registrator::saveCroppedFixedImageToDisk( const std::string path ) const
{
  std::vector<int> compression_params;
  compression_params.push_back(cv::IMWRITE_PNG_COMPRESSION);
  compression_params.push_back(9);

  bool result = false;
  try {
    cv::Mat img = cv::imdecode( cv::Mat(_vecCroppedFixedImage),
                                cv::IMREAD_UNCHANGED );
    result = cv::imwrite( path, img );
  }
  catch( const cv::Exception& ex ) {
    std::string err{"OpenCV cannot save image: '"};
    err.append( path + "'\n" );
    err.append( ex.what() );
    throw NFRL::Miscue( err );
  }

  if( !result ) {
    std::string err{"OpenCV cannot save image: "};
    err.append( path );
    throw NFRL::Miscue( err );
  }
}


/**
 * @brief The registration metadata (object) is loaded in real time throughout
 *  the registration process.
 *
 * Therefore, it is available to the user as either XML or custom type.
 * 
 * To preclude OpenCV from the API, and to simplify stringification of the
 * rotation matrix, the supporting struct (type) was made "private" to the NFRL.
 * This way, the rotation matrix as calculated by OpenCV could be used directly.
 * 
 * Per the template for the generated XML output (below), regex search and
 * replace is performed on those lines that have actual data.
 *  - TX is replaced with (==) the calculated translation in the x-direction.
 *  - TY == calculated translation in the y-direction.
 *  - ROTMAT1 == first row of the calculated rotation matrix.
 *  - ROTMAT2 == second row of the calculated rotation matrix.
 *  - ANGLE == actual rotation of Moving image in degrees.
 *  - CENTER == the resulting point of the translation.
 * 
 * The \<registration_control_points\> node contains the four input points that
 * were inputs to the NFRL constructor and subsequently offset by the padding.
 * In other words, these are the control points used to perform the registration
 * using the padded images. 
 * This node also contains the Euclidean distance between the constrained and
 * unconstrained points.  Note that the Euclidean distance between the
 * constrained points always equals zero by design of the rigid-transform.
 * 
 * Per the template below, X is the x-coordinate, Y is the y-coordinate.
 * The first (immediate) number following X and Y is the image number:
 *  - 1 is the first, moving image
 *  - 2 is the second, fixed image
 * 
 * The following (second) number is order of the input coordinates into this
 * NFRL (library).  There are 8 coordinates, two for each input point.
 * (Recall that input points are *across* images: first point from image 1,
 * second point from image 2, third point from image 1, fourth point from
 * image 2).
 * 
 * Therefore, corresponding control-points pairs are pt1::pt2 and pt3::pt4.).
 *  - X11,Y12 is the first control point of the registered images
 *  - X23,Y24 == second control point
 *  - X15,Y16 == third control point
 *  - X27,Y28 == fourth control point
 * 
 * XML template where all of the capitalized data-fields, e.g. `ROTMAT1`, are
 * replaced by the actual data:
 * ```
 * <registration_metadata>
 *   <translation>
 *     <affine_transform>
 *       <rows>2</rows>
 *       <cols>3</cols>
 *       <row>1 0 TX</row>
 *       <row>0 1 TY</row>
 *     </affine_transform>
 *   </translation>
 *   <rotation>
 *     <affine_transform>
 *       <rows>2</rows>
 *       <cols>3</cols>
 *       <row>ROTMAT1</row>
 *       <row>ROTMAT2</row>
 *     </affine_transform>
 *     <angle>ANGLE</angle>
 *     <center_of_rotation>CENTER</center_of_rotation>
 *   </rotation>
 *   <registration_control_points>
 *     <fixed_image>
 *       <constrained_point>X23,Y24</constrained_point>
 *       <unconstrained_point>X27,Y28</unconstrained_point>
 *     </fixed_image>
 *     <moving_image>
 *       <constrained_point>X11,Y12</constrained_point>
 *       <unconstrained_point>X15,Y16</unconstrained_point>
 *     </moving_image>
 *     <euclidean_distance>
 *       <constrained_pair>DIST</constrained_pair>
 *       <unconstrained_pair>DIST</unconstrained_pair>
 *     </euclidean_distance>
 *   </registration_control_points>
 *   <scale_factor>SF</scale_factor>
 *   <image_size>
 *     <src_moving>
 *       <width>WD</width>
 *       <height>HT</height>
 *     </src_moving>
 *     <src_fixed>
 *       <width>WD</width>
 *       <height>HT</height>
 *     </src_fixed>
 *     <transform_padded>
 *       <width>WD</width>
 *       <height>HT</height>
 *     </transform_padded>
 *     <registered>
 *       <width>WD</width>
 *       <height>HT</height>
 *     </registered>
 *   </image_size>
 *   <convert_gray>
 *     <src_moving>NO</src_moving>
 *     <src_fixed>NO</src_fixed>
 *   </convert_gray>
 *   <overlap_roi>
 *     <top_left>X1,Y1</top_left >
 *     <bot_right>X2,Y2</bot_right>
 *   </overlap_roi>
 * </registration_metadata>
 * ```
 * 
 * @param m OUT XML nodes in proper order with metadata inserted
 */
void Registrator::getXmlMetadata( XmlMetadata &m )
{
  buildXmlTagline( m, "<registration_metadata>" );
  buildXmlTagline( m, "  <translation>" );
  buildXmlTagline( m, "    <affine_transform>" );
  buildXmlTagline( m, "      <rows>2</rows>" );
  buildXmlTagline( m, "      <cols>3</cols>" );
  buildXmlTagline( m, "      <row>1 0 VALUX</row>",
                   std::to_string(registrationMetadata.tx) );
  buildXmlTagline( m, "      <row>0 1 VALUX</row>",
                   std::to_string(registrationMetadata.ty) );
  buildXmlTagline( m, "    </affine_transform>" );
  buildXmlTagline( m, "  </translation>" );
  buildXmlTagline( m, "  <rotation>" );
  buildXmlTagline( m, "    <affine_transform>" );
  buildXmlTagline( m, "      <rows>2</rows>" );
  buildXmlTagline( m, "      <cols>3</cols>" );

  std::vector<std::string> vecRotTransform =
    registrationMetadata.getRotationTransform();
  for( size_t i=0; i<vecRotTransform.size(); i++ )
  {
    buildXmlTagline( m, "      <row>VALUX</row>", vecRotTransform[i] );
  }
  buildXmlTagline( m, "    </affine_transform>" );

  double angle = registrationMetadata.angleDiffDegrees;
  std::stringstream stream;
  stream << std::fixed << std::setprecision(1) << angle;  // handles rounding
  buildXmlTagline( m, "    <angle>VALUX</angle>", stream.str() );
  buildXmlTagline( m, "    <center_of_rotation>VALUX</center_of_rotation>",
                   registrationMetadata.centerRot.to_s() );
  buildXmlTagline( m, "  </rotation>" );
  buildXmlTagline( m, "  <registration_control_points>" );
  buildXmlTagline( m, "    <fixed_image>" );
  std::string key{"pt2"};
  buildXmlTagline( m, "      <constrained_point>VALUX</constrained_point>",
                   registrationMetadata.controlPoints.point[key].to_s() );
  key = "pt4";
  buildXmlTagline( m, "      <unconstrained_point>VALUX</unconstrained_point>",
                   registrationMetadata.controlPoints.point[key].to_s() );
  buildXmlTagline( m, "    </fixed_image>" );
  buildXmlTagline( m, "    <moving_image>" );
  key = "pt1";
  buildXmlTagline( m, "      <constrained_point>VALUX</constrained_point>",
                   registrationMetadata.controlPoints.point[key].to_s() );
  key = "pt3";
  buildXmlTagline( m, "      <unconstrained_point>VALUX</unconstrained_point>",
                   registrationMetadata.controlPoints.point[key].to_s() );
  buildXmlTagline( m, "    </moving_image>" );
  buildXmlTagline( m, "    <euclidean_distance>" );
  buildXmlTagline( m, "      <constrained_pair>VALUX</constrained_pair>",
                   registrationMetadata.controlPoints.euclideanDistance.
                     to_s_constrained() );
  buildXmlTagline( m, "      <unconstrained_pair>VALUX</unconstrained_pair>",
                   registrationMetadata.controlPoints.euclideanDistance.
                     to_s_unconstrained() );
  buildXmlTagline( m, "    </euclidean_distance>" );
  buildXmlTagline( m, "  </registration_control_points>" );
  buildXmlTagline( m, "  <scale_factor>" );
  buildXmlTagline( m, "    <value>VALUX</value>",
                   std::to_string( registrationMetadata.scaleFactor.value ) );
  buildXmlTagline( m, "    <direction>VALUX</direction>",
                   registrationMetadata.scaleFactor.getScaleFactorDirection() );
  buildXmlTagline( m, "  </scale_factor>" );
  buildXmlTagline( m, "  <image_size>" );
  buildXmlTagline( m, "    <src_moving>" );
  buildXmlTagline( m, "      <width>VALUX</width>",
                   registrationMetadata.srcMovingImgSize.getWidth() );
  buildXmlTagline( m, "      <height>VALUX</height>",
                   registrationMetadata.srcMovingImgSize.getHeight() );
  buildXmlTagline( m, "    </src_moving>" );
  buildXmlTagline( m, "    <src_fixed>" );
  buildXmlTagline( m, "      <width>VALUX</width>",
                   registrationMetadata.srcFixedImgSize.getWidth() );
  buildXmlTagline( m, "      <height>VALUX</height>",
                   registrationMetadata.srcFixedImgSize.getHeight() );
  buildXmlTagline( m, "    </src_fixed>" );
  buildXmlTagline( m, "    <transform_padded>" );
  buildXmlTagline( m, "      <width>VALUX</width>",
                   registrationMetadata.paddedImgSize.getWidth() );
  buildXmlTagline( m, "      <height>VALUX</height>",
                   registrationMetadata.paddedImgSize.getHeight() );
  buildXmlTagline( m, "    </transform_padded>" );
  buildXmlTagline( m, "    <registered>" );
  buildXmlTagline( m, "      <width>VALUX</width>",
                   registrationMetadata.registeredImgSize.getWidth() );
  buildXmlTagline( m, "      <height>VALUX</height>",
                   registrationMetadata.registeredImgSize.getHeight() );
  buildXmlTagline( m, "    </registered>" );
  buildXmlTagline( m, "  </image_size>" );
  buildXmlTagline( m, "  <convert_gray>" );
  buildXmlTagline( m, "    <src_moving>VALUX</src_moving>",
                   registrationMetadata.convertToGrayscale.img1_to_s() );
  buildXmlTagline( m, "    <src_fixed>VALUX</src_fixed>",
                   registrationMetadata.convertToGrayscale.img2_to_s() );
  buildXmlTagline( m, "  </convert_gray>" );
  buildXmlTagline( m, "  <overlap_roi>" );
  buildXmlTagline( m, "    <top_left>VALUX</top_left>",
                   registrationMetadata.overlapROICorners[0] );
  buildXmlTagline( m, "    <bot_right>VALUX</bot_right>",
                   registrationMetadata.overlapROICorners[1] );
  buildXmlTagline( m, "  </overlap_roi>" );
  buildXmlTagline( m, "</registration_metadata>" );
}


/** @brief Build the XML one line at a time.
 *
 * @param m container for all taglines that comprise the XML metadata
 * @param tagline line of XML to add
 */
void Registrator::buildXmlTagline( XmlMetadata& m, std::string tagline )
{
  m.push_back( tagline );
}


/**
 * @brief Use regex to search and replace the VALUX string in the tagline
 *  template (string).
 *
 * @param m container for all taglines that comprise the XML metadata
 * @param tagline line of XML to add
 * @param datum a registration metadata value
 */
void Registrator::buildXmlTagline( XmlMetadata& m, std::string tagline,
                                   std::string datum )
{
  std::string from{"VALUX"};
  m.push_back( std::regex_replace( tagline, std::regex(from), datum ) );
}


/**
 * @brief The registration metadata (object) is loaded in real time throughout
 *  the registration process.
 *
 * Therefore, it is available to the user as either XML or custom type.
 * To preclude OpenCV from the API, this function's parameter (struct type)
 * contains only basic/universal data types like ints, doubles, vectors,
 * and/or strings.
 *
 * The metadata is "transferred" to the custom struct that is available to
 * the NFRL user.
 *
 * @param m OUT the metadata reference
 */
void Registrator::getMetadata( Registrator::RegistrationMetadata &m ) const
{
  m = registrationMetadata;
}


/**
 * @brief Core method.
 *
 * Prior to registration, the images are padded on all sides with white.
 * This is done to prevent any pixels in the moving image from being "moved"
 * or "registered" outside of the fixed image boundary (else portions of the
 * fingerprint would be "cut off").
 *
 * The moving image is translated and rotated to "match" the fixed image.
 * In other words, the fixed image is "fixed" in space and the moving image
 * is "moved" to align with the fixed.
 *
 * Translation:
 * The first point of the moving image is moved to the first point of the
 * fixed image.
 *
 * Rotation:
 * The angle from the horizontal for each segment in each image is calculated.
 * The difference between these angles is the amount of rotation.  The "origin"
 * of the rotation is the first, selected control point of the fixed image.
 * If the angle difference is negative, the rotation is clockwise; if positive,
 * rotation is counterclockwise.
 *
 * For image padding that results in two images of the same size
 * (width x height):
 * 1. The "target" pad size is based on the sizes of the input images; this
 *  target WxH is then used to calculate the padding for both images resulting
 * in two padded images that are the same size.
 * 2. translate and rotate the MOVING to the FIXED.
 *
 * Prior to calling this function, caller MUST update the corresponding control
 * points and metadata private variables that are passed by reference.  The
 * corresponding control points shall contain the latest set of points.
 * The metadata may be cleared prior to the call of this function; if not,
 * the metadata object shall contain info on all registration attempts.
 *
 * Management of these Registrator object references by the caller supports
 * the registration 'retry' capability.  For retry, the images are the same
 * (and therefore do not need to be reloaded into memory), the set of
 * corresponding control points have been modified, and the corresponding
 * metadata is updated per the retry.
 *
 * If either source image has more than one channel, i.e., is a color image,
 * that image is converted to grayscale(8-bits per pixel); the registration metadata
 * is updated to indicate the conversion.
 *
 * @throw NFRL::Miscue image control-points identical
 * @throw NFRL::Miscue corresponding points (vector) count not-equal to 8
 * @throw NFRL::Miscue OpenCV cannot decode image
 * @throw NFRL::Miscue OpenCV cannot pad image
 * @throw NFRL::Miscue padded images not same size
 * @throw NFRL::Miscue OpenCV cannot colorize padded, fixed image
 * @throw NFRL::Miscue OpenCV cannot perform translation
 * @throw NFRL::Miscue OpenCV cannot perform rotation
 * @throw NFRL::Miscue OpenCV cannot colorize padded-translated-rotated image
 * @throw NFRL::Miscue OpenCV cannot merge overlaid images
 * @throw NFRL::Miscue Registered images overlap region is empty
 * @throw NFRL::Miscue Registered images overlap region does not meet width threshold
 * @throw NFRL::Miscue Registered images overlap region does not meet height threshold
 */
void Registrator::performRegistration()
{
  if( _correspondingPoints.size() != 8 )
  {
    std::string err{"Corresponding points count == "};
    err.append( std::to_string(_correspondingPoints.size()) );
    err.append( ", should be 8" );
    throw NFRL::Miscue( err );
  }
  auto pt1 = cv::Point( _correspondingPoints[0], _correspondingPoints[1] );
  auto pt2 = cv::Point( _correspondingPoints[2], _correspondingPoints[3] );
  auto pt3 = cv::Point( _correspondingPoints[4], _correspondingPoints[5] );
  auto pt4 = cv::Point( _correspondingPoints[6], _correspondingPoints[7] );
  if( pt1 == pt3 ) {
    throw NFRL::Miscue( "Moving image control-points identical, cannot continue" );
  }
  if( pt2 == pt4 ) {
    throw NFRL::Miscue( "Fixed image control-points identical, cannot continue" );
  }
  
  cv::Mat img1, img2;
  try {
    img1 = cv::imdecode( cv::Mat(_imgMoving), cv::IMREAD_GRAYSCALE );
    if( img1.channels() > 1 )
    {
      registrationMetadata.convertToGrayscale.img1 = true;
    }
    registrationMetadata.srcMovingImgSize.set( img1.cols, img1.rows );

    img2 = cv::imdecode( cv::Mat(_imgFixed), cv::IMREAD_GRAYSCALE );
    if( img2.channels() > 1 )
    {
      registrationMetadata.convertToGrayscale.img2 = true;
    }
    registrationMetadata.srcFixedImgSize.set( img2.cols, img2.rows );

    _metadata.push_back( "Source images dimensions:" );
    _metadata.push_back( "  Moving img: " + std::to_string( img1.cols ) + "x"
                         + std::to_string( img1.rows ) + " [WxH]" );
    _metadata.push_back( "  Fixed img:  " + std::to_string( img2.cols ) + "x"
                         + std::to_string( img2.rows ) + " [WxH]" );

  }
  catch( const cv::Exception& ex ) {
    std::string err{"OpenCV cannot decode image: "};
    err.append( ex.what() );
    throw NFRL::Miscue( err );
  }

  // Output the "raw" corresponding points to _metadata.
  // Keep this code here; later on is modified by adding the translate value
  // and then restoring.
  _metadata.push_back( "\nRaw points order: x1 y1 x2 y2 x3 y3 x4 y4" );
  std::string cpRaw{""};
  for( long unsigned i=0; i < _correspondingPoints.size(); i++ )
    { cpRaw.append( std::to_string( _correspondingPoints[i] ) + " " ); }
  _metadata.push_back( cpRaw );


  // ************ START PADDING **************
  // To ensure the final, registered, Moving image does not have any portion
  // of the ridge structure cut off, both images are padded prior to the
  // registration (process).
  // The padding on the left and top MUST be the same for both images, and it
  // follows that the right and bottom (values) fall where they may to ensure
  // padded images are the same size.
  // Therefore, any ODD row or column are “flushed-out” at the right and bottom.
  // The left and top padding (values) are used to “back-out” the padding for
  // any/all registration calculations.
  // The "target" pad size is based on the sizes of the input images; this
  // target WxH is then used to calculate the padding for both images resulting
  // in two padded images that are the same size.
  cv::Mat paddedMovingImg, paddedFixedImg;
    {
      _padDiffMoving.reset();
      _padDiffFixed.reset();

      int targetPadWidth, targetPadHeight;
      targetPadWidth =  img2.cols + ( 2 * img1.cols );
      targetPadHeight = img2.rows + ( 2 * img1.rows );

      _padDiffMoving.top = img1.rows;
      _padDiffFixed.top = _padDiffMoving.top;  // padding top MUST be same

      _padDiffMoving.left = img1.cols;
      _padDiffFixed.left = _padDiffMoving.left;  // padding left MUST be same

      _padDiffMoving.bot = targetPadHeight - img1.rows - _padDiffMoving.top;
      _padDiffFixed.bot  = targetPadHeight - img2.rows - _padDiffFixed.top;

      _padDiffMoving.right = targetPadWidth - img1.cols - _padDiffMoving.left;
      _padDiffFixed.right  = targetPadWidth - img2.cols - _padDiffFixed.left;
      _metadata.push_back( "Moving img padding, Top: " + 
                            std::to_string(_padDiffMoving.top) + ", Bot: " +
                            std::to_string(_padDiffMoving.bot) + ", Left: " +
                            std::to_string(_padDiffMoving.left) + ", Right: " +
                            std::to_string(_padDiffMoving.right) );
      _metadata.push_back( "Fixed img padding,  Top: " +
                            std::to_string(_padDiffFixed.top) + ", Bot: " +
                            std::to_string(_padDiffFixed.bot) + ", Left: " +
                            std::to_string(_padDiffFixed.left) + ", Right: " +
                            std::to_string(_padDiffFixed.right) );
    }
  // ************ END PADDING **************

  try {
    cv::copyMakeBorder( img1, paddedMovingImg,
                        _padDiffMoving.top, _padDiffMoving.bot,
                        _padDiffMoving.left, _padDiffMoving.right,
                        cv::BORDER_CONSTANT, cv::Scalar::all(255) );
    std::vector<int> param(1);
    param[0] = cv::IMWRITE_PNG_STRATEGY_DEFAULT;
    cv::copyMakeBorder( img2, paddedFixedImg,
                        _padDiffFixed.top, _padDiffFixed.bot,
                        _padDiffFixed.left, _padDiffFixed.right,
                        cv::BORDER_CONSTANT, cv::Scalar::all(255) );
  }
  catch( const cv::Exception& ex ) {
    std::string err{"OpenCV cannot pad image: "};
    err.append( ex.what() );
    throw NFRL::Miscue( err );
  }

  if( (paddedMovingImg.cols == paddedFixedImg.cols) &&
      (paddedMovingImg.rows == paddedFixedImg.rows) )
  {
    registrationMetadata.paddedImgSize.set( paddedFixedImg.cols,
                                            paddedFixedImg.rows );
    _metadata.push_back( "Padded images are SAME size:" );
    _metadata.push_back( "New PADDED moving img dimensions: "
                         + std::to_string( paddedMovingImg.cols ) + "x"
                         + std::to_string( paddedMovingImg.rows ) + " [WxH]" );
    _metadata.push_back( "New PADDED fixed img dimensions:  "
                         + std::to_string( paddedFixedImg.cols ) + "x"
                         + std::to_string( paddedFixedImg.rows ) + " [WxH]" );
  }
  else {
    throw NFRL::Miscue( "Padded images not same size" );
  }

  // Convert padded fixed image gray to BGR and then cyan.
  cv::Mat colorPaddedFixedImg( paddedFixedImg.size(), CV_8UC3,
                               cv::Scalar(0, 0, 0) );
  try {
    cv::cvtColor( paddedFixedImg, colorPaddedFixedImg, cv::COLOR_GRAY2RGB );
  }
  catch( const cv::Exception& ex ) {
    std::string err{"OpenCV cannot colorize padded, fixed image: "};
    err.append( ex.what() );
    throw NFRL::Miscue( err );
  }
  colorPaddedFixedImg += cv::Scalar(255,0,255);  // cyan

  // Save the Fixed image input point coordinates with padding as the
  // control points for registration metadata.  Since the Fixed image by
  // design does not "move" in any way, the Fixed image points are available now.
  auto fixedImgPaddedPt1 =
       cv::Point( _correspondingPoints[2] + _padDiffFixed.left,
                  _correspondingPoints[3] + _padDiffFixed.top );
  auto fixedImgPaddedPt2 =
       cv::Point( _correspondingPoints[6] + _padDiffFixed.left,
                  _correspondingPoints[7] + _padDiffFixed.top );

  // ************ END PADDING **************

  // Prep for translation, build the corresponding points objects.
  cv::Point2f cp1 =
              cv::Point2f( static_cast<float>(_correspondingPoints[0]),
                           static_cast<float>(_correspondingPoints[1]) );
  cv::Point2f cp2 =
              cv::Point2f( static_cast<float>(_correspondingPoints[2]),
                           static_cast<float>(_correspondingPoints[3]) );
  NFRL::CorrespondingPointsPair cpp1(cp1, cp2);
  _metadata.push_back( "\n  TRANSLATE" );
  _metadata.push_back( "  Corresp Points Pair ACROSS images: File1 X File2" );
  _metadata.push_back( "    Pair #1: " + cpp1.to_s() );
  cp1 = cv::Point2f( static_cast<float>(_correspondingPoints[4]),
                     static_cast<float>(_correspondingPoints[5]) );
  cp2 = cv::Point2f( static_cast<float>(_correspondingPoints[6]),
                     static_cast<float>(_correspondingPoints[7]) );
  NFRL::CorrespondingPointsPair cpp2(cp1, cp2);
  _metadata.push_back( "    Pair #2: " + cpp2.to_s() );
  // CorrespondingPointsPairs cpps(cpp1, cpp2);


  float tx = static_cast<float>(_correspondingPoints[2] -
                                _correspondingPoints[0]);
  registrationMetadata.tx = static_cast<int>(tx);
  float ty = static_cast<float>(_correspondingPoints[3] -
                                _correspondingPoints[1]);
  registrationMetadata.ty = static_cast<int>(ty);

  _metadata.push_back( "TRANSLATE horizontal (x-dir): " + std::to_string(registrationMetadata.tx) );
  _metadata.push_back( "TRANSLATE vertical   (y-dir): " + std::to_string(registrationMetadata.ty) );
  _metadata.push_back( "New translate coords:   (" +
                        std::to_string(_correspondingPoints[0]+registrationMetadata.tx) + "," +
                        std::to_string(_correspondingPoints[1]+registrationMetadata.ty) + ")" );
  _metadata.push_back( "Fixed control point #1: (" +
                        std::to_string(_correspondingPoints[0]) + "," +
                        std::to_string(_correspondingPoints[1]) + ")" );
  _metadata.push_back( "Fixed control point #2: (" +
                        std::to_string(_correspondingPoints[2]) + "," +
                        std::to_string(_correspondingPoints[3]) + ")" );

  float translationData[6] = { 1, 0, tx, 0, 1, ty };
  _metadata.push_back( "Translation values: x-dir (positive left): " +
                        std::to_string(registrationMetadata.tx) + ", y-dir (positive down): " +
                        std::to_string(registrationMetadata.ty) );

  // instantiate 2 rows 3 cols matrix loaded with translationData of type CV_32F
  cv::Mat translateMatrix( 2, 3, CV_32F, translationData );
  registrationMetadata.translMatrix =
    CVops::cast_translation_matrix( translateMatrix );
  std::string strMatrix = CVops::translation_matrix_to_s( translateMatrix );
  _metadata.push_back( "TRANSLATION MATRIX:\n" );
  _metadata.push_back( strMatrix );

  // translate
  cv::Mat translatedMovingImg( paddedMovingImg.size(), CV_8UC3,
                               cv::Scalar(0, 0, 0) );
  try {
    cv::warpAffine( paddedMovingImg, translatedMovingImg,
                    translateMatrix, translatedMovingImg.size(),
                    cv::INTER_LINEAR, cv::BORDER_CONSTANT,
                    cv::Scalar(255,255,255) );
  }
  catch( const cv::Exception& ex ) {
    std::string err{"OpenCV cannot perform translation: "};
    err.append( ex.what() );
    throw NFRL::Miscue( err );
  }

  _metadata.push_back( "\n  ROTATE" );

  // Prep for rotation.
  // rp := rotation points
  cv::Point2f rp1 =
              cv::Point2f( static_cast<float>(_correspondingPoints[0]),
                           static_cast<float>(_correspondingPoints[1]) );
  cv::Point2f rp2 =
              cv::Point2f( static_cast<float>(_correspondingPoints[4]),
                           static_cast<float>(_correspondingPoints[5]) );
  NFRL::PointsOnImage poi1(rp1, rp2);
  _metadata.push_back( "Corresponding Points Pair #1 SAME (moving) image: " +
                        poi1.to_s("moving") );

  cv::Point2f rp3 =
              cv::Point2f( static_cast<float>(_correspondingPoints[2]),
                           static_cast<float>(_correspondingPoints[3]) );
  cv::Point2f rp4 =
              cv::Point2f( static_cast<float>(_correspondingPoints[6]),
                           static_cast<float>(_correspondingPoints[7]) );
  NFRL::PointsOnImage poi2(rp3, rp4);
  _metadata.push_back( "Corresponding Points Pair #2 SAME (fixed) image: " +
                        poi2.to_s("fixed") + "\n");

  NFRL::PointsOnImages pois(poi1, poi2);
  registrationMetadata.scaleFactor.value = pois.getScaleFactor();
  ScaleFactorDirection dir = img1_to_img2;
  registrationMetadata.scaleFactor.direction = dir;

  // Prep for calculation of the rotation matrix.
  double rotationScale{1.0};
  double angleDiffDegrees = poi2.angleDegrees - poi1.angleDegrees;
  registrationMetadata.angleDiffDegrees = angleDiffDegrees;

  // Output angle data to _metadata for logging.
  auto str = std::to_string(poi1.angleDegrees);
  _metadata.push_back( "Image 1 angle degrees: " + str );
  str = std::to_string(poi2.angleDegrees);
  _metadata.push_back( "Image 2 angle degrees: " + str );
  str = std::to_string(angleDiffDegrees);
  _metadata.push_back( "Image2 - Image1 angle degrees (of rotation): " + str );
  _metadata.push_back( "  Note: negative angle rotates clockwise;" \
                       " positive angle rotates counter-clockwise." );

  // Calculate center of rotation as the first selected point in the moving
  // image plus the calculated padding.
  const int xCenterRotation{_correspondingPoints[2] + _padDiffFixed.left };
  const int yCenterRotation{_correspondingPoints[3] + _padDiffFixed.top };
  registrationMetadata.centerRot.x = xCenterRotation;
  registrationMetadata.centerRot.y = yCenterRotation;
  _metadata.push_back( "Center of rotation: (" +
                        std::to_string( xCenterRotation ) + ", " +
                        std::to_string( yCenterRotation ) + ")" );

  cv::Point2f pointCenterRotation =
              cv::Point2f( static_cast<float>(xCenterRotation),
                           static_cast<float>(yCenterRotation) );
  cv::Mat rotateMatrix =
          cv::getRotationMatrix2D( pointCenterRotation, angleDiffDegrees,
                                   rotationScale );
  registrationMetadata.rotMatrix = CVops::cast_rotation_matrix( rotateMatrix );
  strMatrix = CVops::rotation_matrix_to_s( rotateMatrix );
  _metadata.push_back( "ROTATION MATRIX:\n" );
  _metadata.push_back( strMatrix );

  // rotate
  cv::Mat paddedRegisteredMovingImg( translatedMovingImg.size(),
                                     CV_8UC3, cv::Scalar(0, 0, 0) );
  try {
    cv::warpAffine( translatedMovingImg, paddedRegisteredMovingImg,
                    rotateMatrix, translatedMovingImg.size(),
                    cv::INTER_LINEAR, cv::BORDER_CONSTANT,
                    cv::Scalar(255,255,255) );
  }
  catch( const cv::Exception& ex ) {
    std::string err{"OpenCV cannot perform rotation: "};
    err.append( ex.what() );
    throw NFRL::Miscue( err );
  }

  cv::Mat colorPaddedRegisteredMovingImg( translatedMovingImg.size(),
                                          CV_8UC3, cv::Scalar(0, 0, 0) );
  try {
    cv::cvtColor( paddedRegisteredMovingImg,
                  colorPaddedRegisteredMovingImg,
                  cv::COLOR_GRAY2RGB );
  }
  catch( const cv::Exception& ex ) {
    std::string err{"OpenCV cannot colorize padded-translated-rotated image: "};
    err.append( ex.what() );
    throw NFRL::Miscue( err );
  }
  colorPaddedRegisteredMovingImg += cv::Scalar(0,255,0);  // green


  // Overlay the green, Moving image atop the cyan, Fixed image.
  cv::Mat colorOverlaidRegisteredImages(
          paddedRegisteredMovingImg.size(), CV_8UC3,
          cv::Scalar(0, 0, 0) );
  try {
    cv::addWeighted( colorPaddedRegisteredMovingImg, 0.5,
                     colorPaddedFixedImg, 0.5, 0.0,
                     colorOverlaidRegisteredImages );
  }
  catch( const cv::Exception& ex ) {
    std::string err{"OpenCV cannot merge overlaid images: "};
    err.append( ex.what() );
    throw NFRL::Miscue( err );
  }

  cv::Rect cropROI2;
  try {
    NFRL::OverlapRegisteredImages ori( paddedRegisteredMovingImg,
                                       paddedFixedImg );
    _metadata.push_back( ori.to_s() );
    cropROI2 = ori.getRegionOfInterest();
    registrationMetadata.overlapROICorners = ori.getRegionOfInterestCorners();
    // Retrieve the blob used to calculate ROI coordinates; this makes
    // available the image to this library and (eventually) the user.
    _vecPngBlob = ori.getPngBlob();
  }
  catch( NFRL::Miscue &e )
  {
    throw e;
  }

  // START FINAL output
  try {
    cv::Mat croppedMovingImg =
            CVops::crop_image( paddedRegisteredMovingImg, cropROI2 );
    cv::Mat croppedFixedImg = CVops::crop_image( paddedFixedImg, cropROI2 );
    registrationMetadata.registeredImgSize.set( croppedFixedImg.cols,
                                                croppedFixedImg.rows );

    // Save to array just in case save to disk later.
    std::vector<int> param(1);
    param[0] = cv::IMWRITE_PNG_STRATEGY_DEFAULT;
    cv::imencode(".png", croppedMovingImg, _vecCroppedRegisteredImage, param);
    cv::imencode(".png", croppedFixedImg, _vecCroppedFixedImage, param);
    cv::imencode(".png", colorOverlaidRegisteredImages,
                         _vecColorOverlaidRegisteredImages, param);
    cv::imencode(".png", paddedFixedImg,
                         _vecPaddedFixedImg, param);
    cv::imencode(".png", paddedRegisteredMovingImg,
                         _vecPaddedRegisteredMovingImg, param);
  }
  catch( const cv::Exception& ex ) {
    std::string err{"OpenCV cannot crop or save final images: "};
    err.append( ex.what() );
    throw NFRL::Miscue( err );
  }
  // END FINAL output

  // Save the control points metadata. Three of the four points have been
  // determined earlier in the registration process.  Last point needed is
  // the second point of the Moving image. This point is calculated using the
  // segment length in the Moving image and the angle from horizontal of the
  // Fixed image. Note that y-coordinate increases in downwards direction.
  int trp_x, trp_y;
  trp_x = static_cast<int>(poi1.segmentLength *
          std::cos( poi2.angleDegrees * 3.14159265358979 / 180.0 ));
  trp_y = static_cast<int>(poi1.segmentLength *
          std::sin( poi2.angleDegrees * 3.14159265358979 / 180.0 ));
  trp_x = static_cast<int>(pointCenterRotation.x) + trp_x;
  trp_y = static_cast<int>(pointCenterRotation.y) - trp_y;

  registrationMetadata.controlPoints.
    setControlPoint( 1, xCenterRotation, yCenterRotation );
  registrationMetadata.controlPoints.
    setControlPoint( 2, fixedImgPaddedPt1.x, fixedImgPaddedPt1.y );
  registrationMetadata.controlPoints.
    setControlPoint( 3, trp_x, trp_y );
  registrationMetadata.controlPoints.
    setControlPoint( 4, fixedImgPaddedPt2.x, fixedImgPaddedPt2.y );

  // Calculate the Euclidean distances between the control control points.
  // The unconstrained points are the first-two selected (pair) for translation;
  // the constrained points are the last-two selected pair for rotation.
  auto regPt1 = cv::Point( xCenterRotation, yCenterRotation );
  auto regPt2 = cv::Point( fixedImgPaddedPt1.x, fixedImgPaddedPt1.y );
  NFRL::CorrespondingPointsPair postRegConstrained(regPt1, regPt2);
  double distConstrained = postRegConstrained.distance();
  registrationMetadata.controlPoints.euclideanDistance.
    constrained = distConstrained;

  regPt1 = cv::Point( trp_x, trp_y );
  regPt2 = cv::Point( fixedImgPaddedPt2.x, fixedImgPaddedPt2.y );
  NFRL::CorrespondingPointsPair postRegUnconstrained(regPt1, regPt2);
  double distUnconstrained = postRegUnconstrained.distance();
  registrationMetadata.controlPoints.euclideanDistance.
    unconstrained = distUnconstrained;
}


// START Registrator struct definitions

  /** @brief `WxH`
   *
   * @return image dimensions as WxH */
  std::string Registrator::ImageSize::to_s() const
  {
    std::string s{};
    s = std::to_string( width );
    s.append("x");
    s.append( std::to_string( height) );
    return s;
  }

  /** @brief `x,y`
   *
   * @return coords as a comma-separated string */
  std::string Registrator::Point::to_s() const
  {
    std::string s{};
    s = std::to_string(x);
    s.append(",");
    s.append(std::to_string(y));
    return s;
  }

  /** @brief Insert the coords into vector of ints: in order x, y.
   *
   * @param center vector reference
   */
  void Registrator::Point::to_v( std::vector<int> &center )
  {
    center.clear();
    center.push_back( x );
    center.push_back( y );
  }

  /**
   * @brief Retrieve the rotation transform as string elements of vector.
   *
   * Each element of the returned vector is one row of the transform.
   *
   * @return vector with each row of the transform in each element
   */
  std::vector<std::string> Registrator::RegistrationMetadata
                                      ::getRotationTransform()
  {
    size_t tRows{rotMatrix.size()};
    size_t tCols{rotMatrix[1].size()};
    std::vector<std::string> v;

    std::string sTmp{""};
    std::string sMatrix{""};
    for( size_t i=0; i<tRows; i++ )
    {
      for( size_t j=0; j<tCols; j++ )
      {
        sTmp = std::to_string( rotMatrix[i][j] );
        sMatrix.append(sTmp);
        if( j < tCols-1 )
          sMatrix.append(" ");
      }
      v.push_back( sMatrix );
      sMatrix = "";   // clear it for next row
    }
    return v;
  }

  /**
   * @brief Retrieve the translation transform as string elements of vector.
   *
   * Each element of the returned vector is one row of the transform.
   *
   * @return vector with each row of the transform in each element
   */
  std::vector<std::string> Registrator::RegistrationMetadata
                                      ::getTranslationTransform()
  {
    size_t tRows{translMatrix.size()};
    size_t tCols{translMatrix[1].size()};
    std::vector<std::string> v;

    std::string sTmp{};
    std::string sMatrix{};
    for( size_t i=0; i<tRows; i++ )
    {
      for( size_t j=0; j<tCols; j++ )
      {
        sTmp = std::to_string( translMatrix[i][j] );
        sMatrix.append(sTmp);
        if( j < tCols-1 )
          sMatrix.append(" ");
      }
      v.push_back( sMatrix );
      sMatrix = "";   // clear it for next row
    }
    return v;
  }

  /** @brief Get the point as string in customized point-format.
   *
   * @param pointNum either of 1 | 2 | 3 | 4
   */
  std::string Registrator::RegistrationMetadata
                         ::ControlPoints::getControlPoint( short pointNum )
  {
    std::string key = "pt" + std::to_string(pointNum);
    auto p = point[key];
    return p.to_s();
  }

  /** @brief Set the point coordinates and push into map of control points.
   *
   * @param pointNum either of 1 | 2 | 3 | 4
   * @param x coordinate
   * @param y coordinate
   */
  void Registrator::RegistrationMetadata
                  ::ControlPoints::setControlPoint( short pointNum, int x, int y )
  {
    Registrator::Point p;
    p.x = x;
    p.y = y;
    std::string key = "pt" + std::to_string(pointNum);
    point[key] = p;
  }

  /** @brief For logging, return distance
   *
   * @return constrained-points distance to string: always zero
   */
  std::string Registrator::RegistrationMetadata
                         ::ControlPoints::EuclideanDistance
                         ::to_s_constrained() const
  {
    std::string s{std::to_string(constrained)};
    return s;
  }

  /** @brief For logging, return distance
   *
   * @return unconstrained-points distance to string
   */
  std::string Registrator::RegistrationMetadata
                         ::ControlPoints::EuclideanDistance
                         ::to_s_unconstrained() const
  {
    std::string s{std::to_string(unconstrained)};
    return s;
  }

  /** @brief Quick check if either image was converted.
   *
   * @return true if either image converted, false otherwise
   */
  bool Registrator::RegistrationMetadata::ConvertToGrayscale::any() const
  {
    if( img1 || img2 )
      return true;
    else
      return false;
  }

  /** @return "YES" if image was converted to grayscale, "NO" otherwise. */
  std::string Registrator::RegistrationMetadata
                         ::ConvertToGrayscale::img1_to_s() const
  {
    if( img1 ) return "YES";
    else return "NO";
  }

  /** @return "YES" if image was converted to grayscale, "NO" otherwise. */
  std::string Registrator::RegistrationMetadata
                         ::ConvertToGrayscale::img2_to_s() const
  {
    if( img2 ) return "YES";
    else return "NO";
  }

  /** @brief "Direction" of the ratio.
   *
   *  @return [ img1/img2 | img2/img1 ]
   */
  std::string Registrator::RegistrationMetadata
                         ::ScaleFactor::getScaleFactorDirection() const
  {
    std::string s{};
    switch( direction )
    {
      case img1_to_img2 : s = "img1/img2"; break;
      case img2_to_img1 : s = "img2/img1"; break;
      default           : s = "undefined"; break;
    }
    return s;
  }


// END Registrator struct definitions

/**
 * @return the current versions of this NFRL software and OpenCV
 */
std::string printVersion()
{
  std::string s{ "NFRL (NIST Fingerprint Registration Library) version: " };
  std::string v{ NFRL_VERSION };
  s.append(v);
  s.append( "\nNFRL using OpenCV version: ");
  s.append(CV_VERSION);
  return s;
}

}   // END namespace
